{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DEBATE_URL = 'http://www.presidency.ucsb.edu/debates.php'\n",
    "last_fetched_at = None\n",
    "import json\n",
    "import urllib.request, time, re, random, hashlib\n",
    "import bs4\n",
    "import time\n",
    "import sys\n",
    "import nltk\n",
    "import nltk.data\n",
    "from itertools import combinations\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import bigrams\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import time\n",
    "SAVE_FILE = 'text_dict.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch(url):\n",
    "    \"\"\"Load the url compassionately.\"\"\"\n",
    "    \n",
    "    global last_fetched_at\n",
    "    \n",
    "    url_hash = hashlib.sha1(url.encode()).hexdigest()\n",
    "    filename = 'cache/cache-file-{}'.format(url_hash)\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            result = f.read()\n",
    "            if len(result) > 0:\n",
    "                #print(\"Retrieving from cache:\", url)\n",
    "                return result\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #print(\"Loading:\", url)\n",
    "    wait_interval = random.randint(3000,10000)\n",
    "    if last_fetched_at is not None:\n",
    "        now = time.time()\n",
    "        elapsed = now - last_fetched_at\n",
    "        if elapsed < wait_interval:\n",
    "            time.sleep((wait_interval - elapsed)/1000)\n",
    "        \n",
    "    user_agent = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64)'\n",
    "    headers = { 'User-Agent' : user_agent }\n",
    "    req = urllib.request.Request(url, headers = headers)\n",
    "    last_fetched_at = time.time()\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        result = str(response.read())\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(result)\n",
    "    \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def debate_processing(soup):\n",
    "    return_list = []\n",
    "    tables = soup.find_all('table')\n",
    "    \n",
    "    for table in tables:\n",
    "        if table['width'] == '700' and table['bgcolor'] == \"#FFFFFF\":\n",
    "            actual_table = table\n",
    "    rows = actual_table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        try:\n",
    "            link = row.find('a')['href']\n",
    "            cols.append(link)\n",
    "            return_list.append(cols)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words_from_speech(link):\n",
    "    result = fetch(link)\n",
    "    soup = bs4.BeautifulSoup(result,'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_debate_dict():\n",
    "    result = fetch(DEBATE_URL)\n",
    "    soup = bs4.BeautifulSoup(result,'lxml')\n",
    "    debate_list = debate_processing(soup)\n",
    "    debate_dict = {}\n",
    "    for debate in debate_list:\n",
    "\n",
    "        if ' ' not in debate[0]:\n",
    "            debate = debate[1:]\n",
    "        debate_id = ' '.join(debate[:2])\n",
    "        try:\n",
    "            debate_datetime = time.strptime(debate[0].replace('th','').replace('st',''),'%B %d, %Y')\n",
    "        except:\n",
    "            debate_datetime = None\n",
    "\n",
    "        debate_dict[debate_id] = {}\n",
    "        debate_dict[debate_id]['link'] = debate[2]\n",
    "        debate_dict[debate_id]['time'] = debate_datetime \n",
    "        \n",
    "        try:\n",
    "            debate_dict[debate_id]['soup'] = get_words_from_speech(debate[2])\n",
    "        except:\n",
    "            debate_dict[debate_id]['soup'] = None\n",
    "        \n",
    "    return debate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_politician_names(debate_dict):\n",
    "    for key in debate_dict.keys():\n",
    "        raw = get_soup_text(debate_dict[key])\n",
    "        raw = raw.replace(\"--\", \". \")\n",
    "        sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        sents = sent_detector.tokenize(raw.strip())\n",
    "\n",
    "        #find candidate names, most commonly repeated first words of sentences, not common words\n",
    "        colon_names = []\n",
    "        period_names = []\n",
    "\n",
    "        #get names from before colons\n",
    "        for sent in sents:\n",
    "            if ':' in sent:\n",
    "                sent = sent.split(':')\n",
    "                possible_name = sent[0] + \":\"\n",
    "                possible_name_no_paren = remove_paren(possible_name).strip()\n",
    "                if (len(possible_name_no_paren)<25) & (len(possible_name_no_paren)>2):\n",
    "                    colon_names.append(possible_name_no_paren)\n",
    "\n",
    "        fdist1 = FreqDist(colon_names)\n",
    "        fdist1_above_5 = [name[0] for name in fdist1.most_common(15) if name[1]>5]\n",
    "        \n",
    "        #get names before periods\n",
    "        for sent in sents:\n",
    "            if len(nltk.word_tokenize(sent))<5:\n",
    "                possible_name = sent\n",
    "                possible_name_no_paren = remove_paren(possible_name).strip()\n",
    "                if (len(possible_name_no_paren)<25) & (len(possible_name_no_paren)>2):\n",
    "                    period_names.append(possible_name_no_paren)\n",
    "                    \n",
    "        fdist2 = FreqDist(period_names)\n",
    "        fdist2_above_15 = [name[0] for name in fdist2.most_common(15) if name[1]>15]\n",
    "    \n",
    "        #add names to dict\n",
    "        colon_name_highest_freq = fdist1.most_common(1)[0][1]\n",
    "        if colon_name_highest_freq > 20 :\n",
    "            debate_dict[key]['names'] = fdist1_above_5\n",
    "        else:\n",
    "            debate_dict[key]['names'] = fdist2_above_15\n",
    "            \n",
    "    return debate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_soup_text(dbt):\n",
    "    raw = dbt['soup'].get_text()\n",
    "    raw = raw.replace(\"\\\\\", \"\")\n",
    "    raw = raw.replace(\".\", \". \")\n",
    "    raw = raw.replace(\"?\", \"? \")\n",
    "    raw = raw.replace(\"!\", \"! \")\n",
    "    raw = raw.replace(\"  \", \" \")\n",
    "    raw = raw.replace(\"-\", \"- \")\n",
    "    raw = raw.replace(\"â€¦\", \". \")\n",
    "    raw = raw.replace(\"...\", \". \")\n",
    "    return raw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_paren(name):\n",
    "    return_name = ''\n",
    "    skip1c = 0\n",
    "    skip2c = 0\n",
    "    for i in name:\n",
    "        if i == '[':\n",
    "            skip1c += 1\n",
    "        elif i == '(':\n",
    "            skip2c += 1\n",
    "        elif i == ']' and skip1c > 0:\n",
    "            skip1c -= 1\n",
    "        elif i == ')'and skip2c > 0:\n",
    "            skip2c -= 1\n",
    "        elif skip1c == 0 and skip2c == 0:\n",
    "            return_name += i\n",
    "    return return_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def clean_dirty_name_lookup(names):\n",
    "    \n",
    "    lookup_dict = {}\n",
    "    \n",
    "    for name in names:\n",
    "        clean_name = name.split()[-1].upper().replace('.','').replace(')','').replace(';','').replace(':','')\n",
    "        lookup_dict[name] = clean_name\n",
    "    \n",
    "    return lookup_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_election_year(year, dbt):\n",
    "    year = dbt['time'].tm_year\n",
    "    year_mod = year % 4\n",
    "    if year_mod == 0:\n",
    "        election_year = year\n",
    "    else:\n",
    "        election_year = year + (4 - year_mod)\n",
    "    return election_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_names(debate_dict):\n",
    "    # Add debate year\n",
    "    name_years = {}\n",
    "    for dbt in debate_dict.keys():\n",
    "        time = debate_dict[dbt]['time']\n",
    "\n",
    "        # Get election year\n",
    "        if time:\n",
    "            election_year = get_election_year(time.tm_year, debate_dict[dbt])\n",
    "        else:\n",
    "            election_year = 'Uncertain Year'\n",
    "        debate_dict[dbt]['election_year'] = election_year\n",
    "\n",
    "        # Add new set of names from debate to name_years dict\n",
    "        if election_year not in name_years:\n",
    "            name_years[election_year] = {'names':set()}\n",
    "\n",
    "        names = set(debate_dict[dbt][\"names\"])\n",
    "        name_years[election_year]['names'] = name_years[election_year]['names'].union(names)\n",
    "\n",
    "    # Reduce all names in one year to a single name\n",
    "    for year in name_years:\n",
    "        name_years[year]['lookup'] = clean_dirty_name_lookup(name_years[year]['names'])\n",
    "\n",
    "    # Add lookup dictionary to debate dictionary\n",
    "    for dbt in debate_dict.keys():\n",
    "        election_year = debate_dict[dbt]['election_year']\n",
    "        debate_dict[dbt]['lookup'] = name_years[election_year]['lookup']\n",
    "        debate_dict[dbt]['clean_names'] = debate_dict[dbt]['lookup'].values()\n",
    "    \n",
    "    return debate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def attribute_text(debate_dict):\n",
    "    #make year/candidate dictionary for text\n",
    "    cand_text_dict = {}\n",
    "    for dbt in debate_dict.keys():\n",
    "        year = debate_dict[dbt]['election_year']\n",
    "        cand_text_dict[year] = {}\n",
    "        for cand in debate_dict[dbt][\"clean_names\"]:\n",
    "            cand_text_dict[year][cand] = {}\n",
    "            cand_text_dict[year][cand]['full_text'] = \"\"\n",
    "    \n",
    "    #fill year/candidate dictionary\n",
    "    for dbt in debate_dict.keys():\n",
    "        #set variables\n",
    "        year = debate_dict[dbt][\"election_year\"]\n",
    "        names = debate_dict[dbt][\"names\"]\n",
    "        if \"write\" in names:\n",
    "            names.remove('write')\n",
    "        \n",
    "        #get debate soup\n",
    "        raw = get_soup_text(debate_dict[dbt])\n",
    "        \n",
    "        #tokenize sents\n",
    "        for name in names:\n",
    "            raw = raw.replace(name, \". \" + name)\n",
    "        sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "        sents = sent_detector.tokenize(raw.strip())\n",
    "        \n",
    "        #loop through sents\n",
    "        current_speaker = \"\"\n",
    "        got_first_speaker = False\n",
    "        for sent in sents:\n",
    "            new_speaker = (len([name for name in names if name in sent])>0)\n",
    "            if(new_speaker):\n",
    "                got_first_speaker = True\n",
    "                current_speaker_dirty = [name for name in names if name in sent][0]\n",
    "                current_speaker = debate_dict[dbt][\"lookup\"][current_speaker_dirty]\n",
    "            \n",
    "            if(got_first_speaker):\n",
    "                sent_no_name = sent.replace(current_speaker_dirty, \"\")\n",
    "                cand_text_dict[year][current_speaker]['full_text'] = (cand_text_dict[year][current_speaker]['full_text'] + \" \" + sent_no_name)\n",
    "\n",
    "    return cand_text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity_model(cand_text_dict):\n",
    "    dumbWords = stopwords.words('english')\n",
    "    political_positions = ['Governor', 'Senator', 'President']\n",
    "    \n",
    "    \n",
    "    #loop through election years\n",
    "    for year in cand_text_dict.keys():\n",
    "        #loop through candidates\n",
    "        for cand in cand_text_dict[year].keys():\n",
    "            #print(year, cand)\n",
    "        \n",
    "            tokens = nltk.word_tokenize(cand_text_dict[year][cand]['full_text'])\n",
    "            text = nltk.Text(tokens)\n",
    "            fdist_tokens = FreqDist(tokens)\n",
    "            \n",
    "            special_words = [word for word in tokens if len(word)>4 and fdist_tokens[word]>=5 \n",
    "                             and wordnet.synsets(word) and word not in political_positions]\n",
    "            cand_text_dict[year][cand][\"special_words\"] = special_words\n",
    "            \n",
    "            special_words_no_caps = [word for word in tokens if len(word)>4 and fdist_tokens[word]>=5 \n",
    "                             and wordnet.synsets(word) and word[0].islower()]\n",
    "            cand_text_dict[year][cand][\"special_words_no_caps\"] = special_words_no_caps\n",
    "            \n",
    "            if len(text)>0:\n",
    "                #avg word len\n",
    "                sum_len = sum([len(word) for word in text])\n",
    "                cand_text_dict[year][cand][\"avg_word_len\"] = sum_len/len(text)\n",
    "                \n",
    "                #avg word len, no stopwords\n",
    "                text_no_dumbWords = [word for word in text if word not in dumbWords]\n",
    "                sum_len = sum([len(word) for word in text_no_dumbWords])\n",
    "                cand_text_dict[year][cand][\"avg_word_len_no_stopword\"] = sum_len/len(text_no_dumbWords)\n",
    "                \n",
    "                #lex diversity                \n",
    "                cand_text_dict[year][cand][\"lex_diversity_no_stopword\"] = (len(set(text_no_dumbWords)) / len(text_no_dumbWords))\n",
    "            \n",
    "            bgrms = list(bigrams(text))\n",
    "            fdist_bgrms = FreqDist(bgrms)\n",
    "            special_bgrms = [bgm for bgm in bgrms if fdist_bgrms[bgm]>2 \n",
    "                             and wordnet.synsets(bgm[0]) and wordnet.synsets(bgm[1])]\n",
    "            cand_text_dict[year][cand][\"special_bgrms\"] = special_bgrms\n",
    "            \n",
    "            special_bgrms_no_caps = [bgm for bgm in bgrms if fdist_bgrms[bgm]>2 \n",
    "                             and wordnet.synsets(bgm[0]) and wordnet.synsets(bgm[1]) \n",
    "                                     and bgm[0][0].islower() and bgm[1][0].islower()]\n",
    "            cand_text_dict[year][cand][\"special_bgrms_no_caps\"] = special_bgrms_no_caps\n",
    "            \n",
    "            special_bgrms_no_caps_stopwords = [bgm for bgm in bgrms if fdist_bgrms[bgm]>2 \n",
    "                             and wordnet.synsets(bgm[0]) and wordnet.synsets(bgm[1]) \n",
    "                                     and bgm[0][0].islower() and bgm[1][0].islower()\n",
    "                                              and bgm[0] not in dumbWords and bgm[1] not in dumbWords]\n",
    "            cand_text_dict[year][cand][\"special_bgrms_no_caps_stopwords\"] = special_bgrms_no_caps_stopwords\n",
    "            \n",
    "    return cand_text_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main_function(filename):\n",
    "    debate_dict = get_debate_dict()\n",
    "\n",
    "    #find the names of the participants\n",
    "    debate_dict = find_politician_names(debate_dict)\n",
    "\n",
    "    #clean names and years for comparison within electoral years\n",
    "    debate_dict = clean_names(debate_dict)\n",
    "\n",
    "    #compile all text by candidate-year\n",
    "    cand_text_dict = attribute_text(debate_dict)\n",
    "\n",
    "    #create a model of text similarity\n",
    "    cand_text_dict = similarity_model(cand_text_dict)\n",
    "\n",
    "    with open(filename, 'w') as fp:\n",
    "        json.dump(cand_text_dict, fp)\n",
    "    return cand_text_dict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cand_text_dict = main_function(SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['WRITE', 'WHITE', 'PRESIDENT', 'MASHEK', 'NEWMAN', 'VANOCUR', 'WALTERS', 'BUSH', 'BOYD', 'MONDALE', 'FERRARO', 'QUARLES'])\n"
     ]
    }
   ],
   "source": [
    "print(cand_text_dict[1984].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('federal', 'government'), 13)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(cand_text_dict[1960]['NIXON']['special_bgrms_no_caps_stopwords']).most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('foreign', 'policy'), 12),\n",
       " (('tax', 'reduction'), 9),\n",
       " (('present', 'time'), 8),\n",
       " (('tax', 'bill'), 7),\n",
       " (('best', 'interests'), 6),\n",
       " (('defense', 'budget'), 6),\n",
       " (('make', 'certain'), 5),\n",
       " (('good', 'job'), 5),\n",
       " (('year', 'ago'), 4),\n",
       " (('mining', 'bill'), 4),\n",
       " (('cruise', 'missiles'), 4),\n",
       " (('million', 'metric'), 4),\n",
       " (('made', 'available'), 4),\n",
       " (('billion', 'tax'), 4),\n",
       " (('strip', 'mining'), 4),\n",
       " (('metric', 'tons'), 4),\n",
       " (('net', 'result'), 4),\n",
       " (('constitutional', 'amendment'), 4),\n",
       " (('million', 'people'), 4),\n",
       " (('tax', 'relief'), 4)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqDist(cand_text_dict[1976]['PRESIDENT']['special_bgrms_no_caps_stopwords']).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['special_bgrms_no_caps_stopwords', 'lex_diversity_no_stopword', 'avg_word_len_no_stopword', 'special_bgrms_no_caps', 'special_words', 'avg_word_len', 'special_words_no_caps', 'full_text', 'special_bgrms'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_text_dict[1984]['BUSH'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_score_and_data_matrix(debate_dict,var_list,distance_method,weights=None):\n",
    "    \n",
    "    # locations of id and text in score dataframe\n",
    "    cand_scores = []\n",
    "    for year in debate_dict:\n",
    "        # Build each row of dataframe\n",
    "        for candidate in debate_dict[year]:\n",
    "            cand_year_dict = debate_dict[year][candidate]\n",
    "            cand_id = candidate + '_' + str(year)\n",
    "            var_score_list = [cand_year_dict[x] for x in cand_year_dict if x in var_list]\n",
    "            cand_scores.append([cand_id,cand_year_dict['full_text']] + var_score_list)\n",
    "            \n",
    "    # build normalized dataframe with name and text as first columns, var_list as col keys\n",
    "    cand_df = normalize_scores(cand_scores,var_list)   \n",
    "\n",
    "    \n",
    "    tfidf_freq = get_tfidf_vectors(cand_df['full_text'])\n",
    "    tf_cols = list(tfidf_freq.columns)\n",
    "    df = pd.concat([cand_df,tfidf_freq],axis=1)\n",
    "\n",
    "    \n",
    "    num_rows = len(df)\n",
    "    dist_dict = {}\n",
    "    # Loop over all combinations and calculate distances\n",
    "    for i in range(num_rows-1):\n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "        for j in range(i+1,num_rows):\n",
    "            \n",
    "            # default to equal weights\n",
    "            if weights == None:\n",
    "                weights = [1]*(len(var_list) + 1)\n",
    "            \n",
    "            name1 = df.ix[i]['cand_name']\n",
    "            name2 = df.ix[j]['cand_name']\n",
    "            score = calculate_score(df.ix[i],df.ix[j],weights,var_list,tf_cols,distance_method)\n",
    "            \n",
    "\n",
    "            # fill both sides of dictionary with relative distances\n",
    "\n",
    "            if name1 not in dist_dict:\n",
    "                dist_dict[name1] = {}\n",
    "            if name2 not in dist_dict:\n",
    "                dist_dict[name2] = {}\n",
    "            dist_dict[name1][name2] = score\n",
    "            dist_dict[name2][name1] = score\n",
    "\n",
    "\n",
    "    return df,dist_dict        \n",
    "\n",
    "def calculate_score(row1,row2,weights,var_list,tfidf_cols,distance_method):\n",
    "    \n",
    "    tfidf_weight = weights['tfidf']\n",
    "    var_weights = weights['var']\n",
    "    \n",
    "    \n",
    "    # equal weight to all tfidf features\n",
    "    tfidf_weight_list = [tfidf_weight / len(tfidf_cols)]*len(tfidf_cols)\n",
    "    \n",
    "    new_weights = [tfidf_weight_list,var_weights]\n",
    "    columns = [tfidf_cols,var_list]\n",
    "    r1_weighted = weight_rows(row1,columns,new_weights)\n",
    "    r2_weighted = weight_rows(row2,columns,new_weights)\n",
    "\n",
    "    return distance_method(r1_weighted,r2_weighted)\n",
    "\n",
    "def weight_rows(row,col_list,weight_list):\n",
    "    rv = np.array(row[col_list[0]]) * weight_list[0]\n",
    "    for i in range(1,len(col_list)):\n",
    "        rv = np.hstack([rv,np.array(row[col_list[i]]*weight_list[i])])\n",
    "    \n",
    "    return rv\n",
    "\n",
    "def normalize_scores(list_of_scores,var_list):\n",
    "    \n",
    "    df = pd.DataFrame(list_of_scores)\n",
    "    \n",
    "    # Rename columns\n",
    "    col_dict = {0:'cand_name',1:'full_text'}\n",
    "    for i, var in enumerate(var_list):\n",
    "        col_dict[i+2] = var\n",
    "    df = df.rename(columns=col_dict)\n",
    "    df.fillna(0,inplace=True) # none existent should be 0\n",
    "    \n",
    "    \n",
    "    df[var_list] = normalize(df[var_list],'l1',axis=0)\n",
    "    return df\n",
    "\n",
    "def get_tfidf_vectors(list_of_texts):\n",
    "    # Used basis of code from hw 1\n",
    "    vectorizer = TfidfVectorizer(analyzer = \"word\",\n",
    "                                 tokenizer = None,\n",
    "                                 preprocessor = None,\n",
    "                                 stop_words = stopwords.words('english'),\n",
    "                                 lowercase= True,\n",
    "                                 max_features = 1000,\n",
    "                                 smooth_idf = True) # Enable smoothing\n",
    "    compressed_vectors = vectorizer.fit_transform(list_of_texts)\n",
    "    df = pd.DataFrame(compressed_vectors.toarray())\n",
    "    df.columns = vectorizer.get_feature_names()\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_distance_matrix(raw_scores,dist_dict):\n",
    "    names = list(raw_scores['cand_name'])\n",
    "    score_compare = pd.DataFrame(index=names,columns=names)\n",
    "    for name in names:\n",
    "        new_col = []\n",
    "        for compare_name in names:\n",
    "            try:\n",
    "                new_col.append(dist_dict[name][compare_name])\n",
    "            except:\n",
    "                new_col.append(np.nan)\n",
    "        score_compare[name] = new_col\n",
    "    score_compare.fillna(np.nan,inplace=True)\n",
    "    \n",
    "    rv = score_compare.merge(raw_scores,left_index=True,right_on='cand_name')\n",
    "    rv['year_num'] = rv['cand_name'].apply(lambda x: x.split('_')[1])\n",
    "    \n",
    "    return rv.set_index('cand_name')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n"
     ]
    }
   ],
   "source": [
    "added_fields = ['cand_name','full_text']\n",
    "var_names = ['lex_diversity_no_stopword','avg_word_len_no_stopword']\n",
    "weights = {'var':[1,1],'tfidf':1}\n",
    "raw_scores,dist_dict = build_score_and_data_matrix(cand_text_dict,var_names,cosine,weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_df = add_clusters(raw_scores,added_fields)\n",
    "score_df = build_distance_matrix(cluster_df,dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_clusters(df,added_fields):\n",
    "    # cluster only on data on speeches\n",
    "    kmeans = KMeans()    \n",
    "    kmeans.fit_predict(df.drop(added_fields,axis=1))\n",
    "    df['clusters'] = kmeans.labels_\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HARWOOD_2016</th>\n",
       "      <th>REGAN_2016</th>\n",
       "      <th>HUCKABEE_2016</th>\n",
       "      <th>MACCALLUM_2016</th>\n",
       "      <th>FIORINA_2016</th>\n",
       "      <th>CLINTON_2016</th>\n",
       "      <th>WRITE_2016</th>\n",
       "      <th>EPPERSON_2016</th>\n",
       "      <th>MUIR_2016</th>\n",
       "      <th>UNKNOWN_2016</th>\n",
       "      <th>...</th>\n",
       "      <th>www</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>clusters</th>\n",
       "      <th>year_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cand_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HARWOOD_2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.056720</td>\n",
       "      <td>0.050591</td>\n",
       "      <td>0.065202</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072182</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>0.145370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037513</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REGAN_2016</th>\n",
       "      <td>0.031153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082216</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.087203</td>\n",
       "      <td>0.148383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048220</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>0.106666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUCKABEE_2016</th>\n",
       "      <td>0.056720</td>\n",
       "      <td>0.082216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106893</td>\n",
       "      <td>0.027428</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.140922</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>0.239102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011801</td>\n",
       "      <td>0.025915</td>\n",
       "      <td>0.066378</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.009994</td>\n",
       "      <td>0.017561</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MACCALLUM_2016</th>\n",
       "      <td>0.050591</td>\n",
       "      <td>0.017359</td>\n",
       "      <td>0.106893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111284</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037138</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FIORINA_2016</th>\n",
       "      <td>0.065202</td>\n",
       "      <td>0.087203</td>\n",
       "      <td>0.027428</td>\n",
       "      <td>0.111284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152210</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.252546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006045</td>\n",
       "      <td>0.033189</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.055735</td>\n",
       "      <td>0.043116</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLINTON_2016</th>\n",
       "      <td>0.108198</td>\n",
       "      <td>0.148383</td>\n",
       "      <td>0.036874</td>\n",
       "      <td>0.188375</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.240663</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>0.364853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>0.011478</td>\n",
       "      <td>0.023757</td>\n",
       "      <td>0.052203</td>\n",
       "      <td>0.006627</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.057036</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WRITE_2016</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPPERSON_2016</th>\n",
       "      <td>0.072182</td>\n",
       "      <td>0.048220</td>\n",
       "      <td>0.140922</td>\n",
       "      <td>0.037138</td>\n",
       "      <td>0.152210</td>\n",
       "      <td>0.240663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143906</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048185</td>\n",
       "      <td>0.044880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MUIR_2016</th>\n",
       "      <td>0.043685</td>\n",
       "      <td>0.065107</td>\n",
       "      <td>0.052628</td>\n",
       "      <td>0.086792</td>\n",
       "      <td>0.053909</td>\n",
       "      <td>0.064454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.014104</td>\n",
       "      <td>0.019357</td>\n",
       "      <td>0.032453</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN_2016</th>\n",
       "      <td>0.145370</td>\n",
       "      <td>0.106666</td>\n",
       "      <td>0.239102</td>\n",
       "      <td>0.080431</td>\n",
       "      <td>0.252546</td>\n",
       "      <td>0.364853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050303</td>\n",
       "      <td>0.239277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAUL_2016</th>\n",
       "      <td>0.053152</td>\n",
       "      <td>0.078912</td>\n",
       "      <td>0.024077</td>\n",
       "      <td>0.102088</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>0.045702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136616</td>\n",
       "      <td>0.052091</td>\n",
       "      <td>0.229498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029990</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.026836</td>\n",
       "      <td>0.017280</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CARSON_2016</th>\n",
       "      <td>0.053916</td>\n",
       "      <td>0.073268</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.094837</td>\n",
       "      <td>0.026154</td>\n",
       "      <td>0.043937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125818</td>\n",
       "      <td>0.053027</td>\n",
       "      <td>0.217820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>0.020679</td>\n",
       "      <td>0.048150</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004671</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MITCHELL_2016</th>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.043121</td>\n",
       "      <td>0.091166</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.095094</td>\n",
       "      <td>0.146006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056341</td>\n",
       "      <td>0.067644</td>\n",
       "      <td>0.110011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUICK_2016</th>\n",
       "      <td>0.017382</td>\n",
       "      <td>0.034750</td>\n",
       "      <td>0.055024</td>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.064033</td>\n",
       "      <td>0.102818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076720</td>\n",
       "      <td>0.045160</td>\n",
       "      <td>0.150354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032695</td>\n",
       "      <td>0.030453</td>\n",
       "      <td>0.045755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RUBIO_2016</th>\n",
       "      <td>0.096153</td>\n",
       "      <td>0.131588</td>\n",
       "      <td>0.031477</td>\n",
       "      <td>0.168343</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.025282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217901</td>\n",
       "      <td>0.061831</td>\n",
       "      <td>0.332453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042576</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.078709</td>\n",
       "      <td>0.011323</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEBB_2016</th>\n",
       "      <td>0.039929</td>\n",
       "      <td>0.035080</td>\n",
       "      <td>0.063041</td>\n",
       "      <td>0.038948</td>\n",
       "      <td>0.069680</td>\n",
       "      <td>0.127725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.079083</td>\n",
       "      <td>0.105456</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.101815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COONEY_2016</th>\n",
       "      <td>0.063727</td>\n",
       "      <td>0.042285</td>\n",
       "      <td>0.131910</td>\n",
       "      <td>0.031544</td>\n",
       "      <td>0.141203</td>\n",
       "      <td>0.222854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023448</td>\n",
       "      <td>0.126714</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEMMER_2016</th>\n",
       "      <td>0.030417</td>\n",
       "      <td>0.021025</td>\n",
       "      <td>0.094064</td>\n",
       "      <td>0.029362</td>\n",
       "      <td>0.101505</td>\n",
       "      <td>0.172382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038201</td>\n",
       "      <td>0.079846</td>\n",
       "      <td>0.088591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>0.078417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SANDERS_2016</th>\n",
       "      <td>0.122347</td>\n",
       "      <td>0.162852</td>\n",
       "      <td>0.045489</td>\n",
       "      <td>0.205776</td>\n",
       "      <td>0.050499</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258805</td>\n",
       "      <td>0.074158</td>\n",
       "      <td>0.386896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.031494</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.072722</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.042682</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUINTANILLA_2016</th>\n",
       "      <td>0.032371</td>\n",
       "      <td>0.020972</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>0.027143</td>\n",
       "      <td>0.079114</td>\n",
       "      <td>0.127393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075837</td>\n",
       "      <td>0.045596</td>\n",
       "      <td>0.142869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058385</td>\n",
       "      <td>0.015539</td>\n",
       "      <td>0.042654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.013159</td>\n",
       "      <td>0.011561</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAVUTO_2016</th>\n",
       "      <td>0.032493</td>\n",
       "      <td>0.020852</td>\n",
       "      <td>0.063937</td>\n",
       "      <td>0.024804</td>\n",
       "      <td>0.070433</td>\n",
       "      <td>0.117501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070201</td>\n",
       "      <td>0.040889</td>\n",
       "      <td>0.137403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.011755</td>\n",
       "      <td>0.010328</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IFILL_2016</th>\n",
       "      <td>0.053205</td>\n",
       "      <td>0.026105</td>\n",
       "      <td>0.108058</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.113345</td>\n",
       "      <td>0.184109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035729</td>\n",
       "      <td>0.083043</td>\n",
       "      <td>0.080271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COOPER_2016</th>\n",
       "      <td>0.035955</td>\n",
       "      <td>0.048070</td>\n",
       "      <td>0.058958</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.061291</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102718</td>\n",
       "      <td>0.025599</td>\n",
       "      <td>0.183372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027074</td>\n",
       "      <td>0.025217</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007338</td>\n",
       "      <td>6</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUSH_2016</th>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.108629</td>\n",
       "      <td>0.027372</td>\n",
       "      <td>0.141228</td>\n",
       "      <td>0.027919</td>\n",
       "      <td>0.031554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185435</td>\n",
       "      <td>0.056238</td>\n",
       "      <td>0.294183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>0.011691</td>\n",
       "      <td>0.039202</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.003038</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BASH_2016</th>\n",
       "      <td>0.026614</td>\n",
       "      <td>0.047399</td>\n",
       "      <td>0.059726</td>\n",
       "      <td>0.068106</td>\n",
       "      <td>0.061853</td>\n",
       "      <td>0.091509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099350</td>\n",
       "      <td>0.031107</td>\n",
       "      <td>0.180436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.023928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BAKER_2016</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.031608</td>\n",
       "      <td>0.087602</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.090095</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044053</td>\n",
       "      <td>0.070539</td>\n",
       "      <td>0.099221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018163</td>\n",
       "      <td>0.084587</td>\n",
       "      <td>0.038127</td>\n",
       "      <td>0.023596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PATAKI_2016</th>\n",
       "      <td>0.040938</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.028756</td>\n",
       "      <td>0.071529</td>\n",
       "      <td>0.036587</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.099758</td>\n",
       "      <td>0.050149</td>\n",
       "      <td>0.179973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.012170</td>\n",
       "      <td>0.022670</td>\n",
       "      <td>0.076638</td>\n",
       "      <td>0.007905</td>\n",
       "      <td>0.093858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KELLY_2016</th>\n",
       "      <td>0.032183</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>0.078682</td>\n",
       "      <td>0.032660</td>\n",
       "      <td>0.085071</td>\n",
       "      <td>0.146838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048118</td>\n",
       "      <td>0.065711</td>\n",
       "      <td>0.097915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015487</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEWITT_2016</th>\n",
       "      <td>0.021877</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>0.062543</td>\n",
       "      <td>0.049406</td>\n",
       "      <td>0.065290</td>\n",
       "      <td>0.110241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074857</td>\n",
       "      <td>0.040809</td>\n",
       "      <td>0.144320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.015655</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCELVEEN_2016</th>\n",
       "      <td>0.058079</td>\n",
       "      <td>0.039455</td>\n",
       "      <td>0.127524</td>\n",
       "      <td>0.030705</td>\n",
       "      <td>0.135089</td>\n",
       "      <td>0.218751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024908</td>\n",
       "      <td>0.114381</td>\n",
       "      <td>0.057662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVANS_2012</th>\n",
       "      <td>0.043022</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.111687</td>\n",
       "      <td>0.028593</td>\n",
       "      <td>0.117265</td>\n",
       "      <td>0.194772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030266</td>\n",
       "      <td>0.104527</td>\n",
       "      <td>0.071957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARWOOD_2012</th>\n",
       "      <td>0.032212</td>\n",
       "      <td>0.018892</td>\n",
       "      <td>0.079721</td>\n",
       "      <td>0.020610</td>\n",
       "      <td>0.088870</td>\n",
       "      <td>0.150510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046810</td>\n",
       "      <td>0.070659</td>\n",
       "      <td>0.102137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012049</td>\n",
       "      <td>0.013577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017532</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNKNOWN_2012</th>\n",
       "      <td>0.070650</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>0.135077</td>\n",
       "      <td>0.035439</td>\n",
       "      <td>0.145333</td>\n",
       "      <td>0.231939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021743</td>\n",
       "      <td>0.138886</td>\n",
       "      <td>0.055019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCELVEEN_2012</th>\n",
       "      <td>0.050556</td>\n",
       "      <td>0.036225</td>\n",
       "      <td>0.114375</td>\n",
       "      <td>0.031262</td>\n",
       "      <td>0.126173</td>\n",
       "      <td>0.203038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026784</td>\n",
       "      <td>0.113072</td>\n",
       "      <td>0.061494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114448</td>\n",
       "      <td>0.032242</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARTIROMO_2012</th>\n",
       "      <td>0.033421</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.069948</td>\n",
       "      <td>0.040258</td>\n",
       "      <td>0.079014</td>\n",
       "      <td>0.134888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052706</td>\n",
       "      <td>0.073083</td>\n",
       "      <td>0.113289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILLIAMS_2012</th>\n",
       "      <td>0.032169</td>\n",
       "      <td>0.021093</td>\n",
       "      <td>0.073922</td>\n",
       "      <td>0.024479</td>\n",
       "      <td>0.082238</td>\n",
       "      <td>0.141261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048686</td>\n",
       "      <td>0.066961</td>\n",
       "      <td>0.107675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009394</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038195</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOV_2012</th>\n",
       "      <td>0.086871</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.160124</td>\n",
       "      <td>0.051113</td>\n",
       "      <td>0.167043</td>\n",
       "      <td>0.255282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038233</td>\n",
       "      <td>0.156506</td>\n",
       "      <td>0.066240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLITZER_2012</th>\n",
       "      <td>0.050793</td>\n",
       "      <td>0.067070</td>\n",
       "      <td>0.050570</td>\n",
       "      <td>0.096012</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.067219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.151299</td>\n",
       "      <td>0.040263</td>\n",
       "      <td>0.247117</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.027491</td>\n",
       "      <td>0.011617</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TUMULTY_2012</th>\n",
       "      <td>0.047938</td>\n",
       "      <td>0.035869</td>\n",
       "      <td>0.095794</td>\n",
       "      <td>0.032618</td>\n",
       "      <td>0.103604</td>\n",
       "      <td>0.177230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033056</td>\n",
       "      <td>0.103230</td>\n",
       "      <td>0.078622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060087</td>\n",
       "      <td>0.111931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HARRIS_2012</th>\n",
       "      <td>0.030233</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.041720</td>\n",
       "      <td>0.086208</td>\n",
       "      <td>0.142201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051034</td>\n",
       "      <td>0.072875</td>\n",
       "      <td>0.110977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029334</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>0.015394</td>\n",
       "      <td>0.019054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MALE_2012</th>\n",
       "      <td>0.060369</td>\n",
       "      <td>0.040085</td>\n",
       "      <td>0.124280</td>\n",
       "      <td>0.031506</td>\n",
       "      <td>0.134924</td>\n",
       "      <td>0.220024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020994</td>\n",
       "      <td>0.126618</td>\n",
       "      <td>0.055647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SANTORUM_2012</th>\n",
       "      <td>0.098707</td>\n",
       "      <td>0.139888</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.180878</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.023634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231137</td>\n",
       "      <td>0.069904</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022115</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.059367</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.012340</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RADDATZ_2012</th>\n",
       "      <td>0.046781</td>\n",
       "      <td>0.036843</td>\n",
       "      <td>0.071147</td>\n",
       "      <td>0.038623</td>\n",
       "      <td>0.082308</td>\n",
       "      <td>0.132105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067549</td>\n",
       "      <td>0.069172</td>\n",
       "      <td>0.126802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020924</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.010981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRESIDENT_2012</th>\n",
       "      <td>0.044080</td>\n",
       "      <td>0.068751</td>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.093641</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.058929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122503</td>\n",
       "      <td>0.051932</td>\n",
       "      <td>0.213219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021248</td>\n",
       "      <td>0.091034</td>\n",
       "      <td>0.008920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086387</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BACHMANN_2012</th>\n",
       "      <td>0.070921</td>\n",
       "      <td>0.098044</td>\n",
       "      <td>0.029932</td>\n",
       "      <td>0.130037</td>\n",
       "      <td>0.031101</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170958</td>\n",
       "      <td>0.057892</td>\n",
       "      <td>0.279174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.049864</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIDEN_2012</th>\n",
       "      <td>0.044681</td>\n",
       "      <td>0.067692</td>\n",
       "      <td>0.028336</td>\n",
       "      <td>0.087498</td>\n",
       "      <td>0.043115</td>\n",
       "      <td>0.066330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114183</td>\n",
       "      <td>0.057872</td>\n",
       "      <td>0.199071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.074860</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>0.005612</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RYAN_2012</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.068603</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.088473</td>\n",
       "      <td>0.042044</td>\n",
       "      <td>0.061545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115125</td>\n",
       "      <td>0.056377</td>\n",
       "      <td>0.205953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009325</td>\n",
       "      <td>0.071670</td>\n",
       "      <td>0.052449</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007897</td>\n",
       "      <td>0.006938</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PERRY_2012</th>\n",
       "      <td>0.082064</td>\n",
       "      <td>0.114059</td>\n",
       "      <td>0.029440</td>\n",
       "      <td>0.148977</td>\n",
       "      <td>0.038610</td>\n",
       "      <td>0.032678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>0.062690</td>\n",
       "      <td>0.301575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028146</td>\n",
       "      <td>0.026489</td>\n",
       "      <td>0.061679</td>\n",
       "      <td>0.013901</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.077780</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HILLER_2012</th>\n",
       "      <td>0.059496</td>\n",
       "      <td>0.039962</td>\n",
       "      <td>0.127413</td>\n",
       "      <td>0.031617</td>\n",
       "      <td>0.137180</td>\n",
       "      <td>0.218016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026279</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.058449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROMNEY_2012</th>\n",
       "      <td>0.142537</td>\n",
       "      <td>0.189734</td>\n",
       "      <td>0.052217</td>\n",
       "      <td>0.236641</td>\n",
       "      <td>0.062980</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.295166</td>\n",
       "      <td>0.091369</td>\n",
       "      <td>0.427696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.037307</td>\n",
       "      <td>0.078850</td>\n",
       "      <td>0.017319</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEMINT_2012</th>\n",
       "      <td>0.045783</td>\n",
       "      <td>0.037178</td>\n",
       "      <td>0.084866</td>\n",
       "      <td>0.038044</td>\n",
       "      <td>0.091869</td>\n",
       "      <td>0.160017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039581</td>\n",
       "      <td>0.094712</td>\n",
       "      <td>0.091226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023507</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRAMER_2012</th>\n",
       "      <td>0.063112</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.036548</td>\n",
       "      <td>0.135347</td>\n",
       "      <td>0.219400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026066</td>\n",
       "      <td>0.130421</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HUNTSMAN_2012</th>\n",
       "      <td>0.058019</td>\n",
       "      <td>0.086321</td>\n",
       "      <td>0.022525</td>\n",
       "      <td>0.115068</td>\n",
       "      <td>0.032886</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149067</td>\n",
       "      <td>0.053436</td>\n",
       "      <td>0.250870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025799</td>\n",
       "      <td>0.048059</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004974</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOLDMAN_2012</th>\n",
       "      <td>0.052159</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.115525</td>\n",
       "      <td>0.036083</td>\n",
       "      <td>0.126235</td>\n",
       "      <td>0.203244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030445</td>\n",
       "      <td>0.115783</td>\n",
       "      <td>0.067885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075152</td>\n",
       "      <td>0.069997</td>\n",
       "      <td>0.078877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAUGHN_2012</th>\n",
       "      <td>0.062003</td>\n",
       "      <td>0.040657</td>\n",
       "      <td>0.133366</td>\n",
       "      <td>0.031278</td>\n",
       "      <td>0.142137</td>\n",
       "      <td>0.227851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023988</td>\n",
       "      <td>0.127324</td>\n",
       "      <td>0.058422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081641</td>\n",
       "      <td>0.045999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MODERATOR_2012</th>\n",
       "      <td>0.030077</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.060911</td>\n",
       "      <td>0.037190</td>\n",
       "      <td>0.065116</td>\n",
       "      <td>0.112681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069967</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>0.140182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034281</td>\n",
       "      <td>0.038316</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAUL_2012</th>\n",
       "      <td>0.103654</td>\n",
       "      <td>0.144535</td>\n",
       "      <td>0.033026</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.042974</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.229302</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.348937</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008602</td>\n",
       "      <td>0.033057</td>\n",
       "      <td>0.067443</td>\n",
       "      <td>0.049565</td>\n",
       "      <td>0.018405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004267</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARRETT_2012</th>\n",
       "      <td>0.033398</td>\n",
       "      <td>0.033726</td>\n",
       "      <td>0.077071</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.081984</td>\n",
       "      <td>0.138273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052902</td>\n",
       "      <td>0.073273</td>\n",
       "      <td>0.114171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAWLENTY_2012</th>\n",
       "      <td>0.037649</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>0.056272</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.064352</td>\n",
       "      <td>0.120259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050482</td>\n",
       "      <td>0.075059</td>\n",
       "      <td>0.113618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIESMAN_2012</th>\n",
       "      <td>0.079834</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>0.158008</td>\n",
       "      <td>0.041454</td>\n",
       "      <td>0.168456</td>\n",
       "      <td>0.265124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>0.159094</td>\n",
       "      <td>0.045152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>351 rows Ã— 1356 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  HARWOOD_2016  REGAN_2016  HUCKABEE_2016  MACCALLUM_2016  \\\n",
       "cand_name                                                                   \n",
       "HARWOOD_2016               NaN    0.031153       0.056720        0.050591   \n",
       "REGAN_2016            0.031153         NaN       0.082216        0.017359   \n",
       "HUCKABEE_2016         0.056720    0.082216            NaN        0.106893   \n",
       "MACCALLUM_2016        0.050591    0.017359       0.106893             NaN   \n",
       "FIORINA_2016          0.065202    0.087203       0.027428        0.111284   \n",
       "CLINTON_2016          0.108198    0.148383       0.036874        0.188375   \n",
       "WRITE_2016                 NaN         NaN            NaN             NaN   \n",
       "EPPERSON_2016         0.072182    0.048220       0.140922        0.037138   \n",
       "MUIR_2016             0.043685    0.065107       0.052628        0.086792   \n",
       "UNKNOWN_2016          0.145370    0.106666       0.239102        0.080431   \n",
       "PAUL_2016             0.053152    0.078912       0.024077        0.102088   \n",
       "CARSON_2016           0.053916    0.073268       0.015345        0.094837   \n",
       "MITCHELL_2016         0.045500    0.043121       0.091166        0.043556   \n",
       "QUICK_2016            0.017382    0.034750       0.055024        0.055022   \n",
       "RUBIO_2016            0.096153    0.131588       0.031477        0.168343   \n",
       "WEBB_2016             0.039929    0.035080       0.063041        0.038948   \n",
       "COONEY_2016           0.063727    0.042285       0.131910        0.031544   \n",
       "HEMMER_2016           0.030417    0.021025       0.094064        0.029362   \n",
       "SANDERS_2016          0.122347    0.162852       0.045489        0.205776   \n",
       "QUINTANILLA_2016      0.032371    0.020972       0.074143        0.027143   \n",
       "CAVUTO_2016           0.032493    0.020852       0.063937        0.024804   \n",
       "IFILL_2016            0.053205    0.026105       0.108058        0.014890   \n",
       "COOPER_2016           0.035955    0.048070       0.058958        0.061914   \n",
       "BUSH_2016             0.078921    0.108629       0.027372        0.141228   \n",
       "BASH_2016             0.026614    0.047399       0.059726        0.068106   \n",
       "BAKER_2016            0.028225    0.031608       0.087602        0.035240   \n",
       "PATAKI_2016           0.040938    0.054131       0.028756        0.071529   \n",
       "KELLY_2016            0.032183    0.030689       0.078682        0.032660   \n",
       "HEWITT_2016           0.021877    0.034149       0.062543        0.049406   \n",
       "MCELVEEN_2016         0.058079    0.039455       0.127524        0.030705   \n",
       "...                        ...         ...            ...             ...   \n",
       "EVANS_2012            0.043022    0.030504       0.111687        0.028593   \n",
       "HARWOOD_2012          0.032212    0.018892       0.079721        0.020610   \n",
       "UNKNOWN_2012          0.070650    0.047138       0.135077        0.035439   \n",
       "MCELVEEN_2012         0.050556    0.036225       0.114375        0.031262   \n",
       "BARTIROMO_2012        0.033421    0.031255       0.069948        0.040258   \n",
       "WILLIAMS_2012         0.032169    0.021093       0.073922        0.024479   \n",
       "GOV_2012              0.086871    0.061198       0.160124        0.051113   \n",
       "BLITZER_2012          0.050793    0.067070       0.050570        0.096012   \n",
       "TUMULTY_2012          0.047938    0.035869       0.095794        0.032618   \n",
       "HARRIS_2012           0.030233    0.032201       0.076438        0.041720   \n",
       "MALE_2012             0.060369    0.040085       0.124280        0.031506   \n",
       "SANTORUM_2012         0.098707    0.139888       0.034127        0.180878   \n",
       "RADDATZ_2012          0.046781    0.036843       0.071147        0.038623   \n",
       "PRESIDENT_2012        0.044080    0.068751       0.031475        0.093641   \n",
       "BACHMANN_2012         0.070921    0.098044       0.029932        0.130037   \n",
       "BIDEN_2012            0.044681    0.067692       0.028336        0.087498   \n",
       "RYAN_2012             0.046974    0.068603       0.028242        0.088473   \n",
       "PERRY_2012            0.082064    0.114059       0.029440        0.148977   \n",
       "HILLER_2012           0.059496    0.039962       0.127413        0.031617   \n",
       "ROMNEY_2012           0.142537    0.189734       0.052217        0.236641   \n",
       "DEMINT_2012           0.045783    0.037178       0.084866        0.038044   \n",
       "CRAMER_2012           0.063112    0.043543       0.124400        0.036548   \n",
       "HUNTSMAN_2012         0.058019    0.086321       0.022525        0.115068   \n",
       "GOLDMAN_2012          0.052159    0.039278       0.115525        0.036083   \n",
       "VAUGHN_2012           0.062003    0.040657       0.133366        0.031278   \n",
       "MODERATOR_2012        0.030077    0.028686       0.060911        0.037190   \n",
       "PAUL_2012             0.103654    0.144535       0.033026        0.182600   \n",
       "GARRETT_2012          0.033398    0.033726       0.077071        0.040756   \n",
       "PAWLENTY_2012         0.037649    0.034620       0.056272        0.042344   \n",
       "LIESMAN_2012          0.079834    0.055498       0.158008        0.041454   \n",
       "\n",
       "                  FIORINA_2016  CLINTON_2016  WRITE_2016  EPPERSON_2016  \\\n",
       "cand_name                                                                 \n",
       "HARWOOD_2016          0.065202      0.108198         NaN       0.072182   \n",
       "REGAN_2016            0.087203      0.148383         NaN       0.048220   \n",
       "HUCKABEE_2016         0.027428      0.036874         NaN       0.140922   \n",
       "MACCALLUM_2016        0.111284      0.188375         NaN       0.037138   \n",
       "FIORINA_2016               NaN      0.043310         NaN       0.152210   \n",
       "CLINTON_2016          0.043310           NaN         NaN       0.240663   \n",
       "WRITE_2016                 NaN           NaN         NaN            NaN   \n",
       "EPPERSON_2016         0.152210      0.240663         NaN            NaN   \n",
       "MUIR_2016             0.053909      0.064454         NaN       0.143906   \n",
       "UNKNOWN_2016          0.252546      0.364853         NaN       0.050303   \n",
       "PAUL_2016             0.034222      0.045702         NaN       0.136616   \n",
       "CARSON_2016           0.026154      0.043937         NaN       0.125818   \n",
       "MITCHELL_2016         0.095094      0.146006         NaN       0.056341   \n",
       "QUICK_2016            0.064033      0.102818         NaN       0.076720   \n",
       "RUBIO_2016            0.035799      0.025282         NaN       0.217901   \n",
       "WEBB_2016             0.069680      0.127725         NaN       0.046703   \n",
       "COONEY_2016           0.141203      0.222854         NaN       0.023448   \n",
       "HEMMER_2016           0.101505      0.172382         NaN       0.038201   \n",
       "SANDERS_2016          0.050499      0.019088         NaN       0.258805   \n",
       "QUINTANILLA_2016      0.079114      0.127393         NaN       0.075837   \n",
       "CAVUTO_2016           0.070433      0.117501         NaN       0.070201   \n",
       "IFILL_2016            0.113345      0.184109         NaN       0.035729   \n",
       "COOPER_2016           0.061291      0.085296         NaN       0.102718   \n",
       "BUSH_2016             0.027919      0.031554         NaN       0.185435   \n",
       "BASH_2016             0.061853      0.091509         NaN       0.099350   \n",
       "BAKER_2016            0.090095      0.157398         NaN       0.044053   \n",
       "PATAKI_2016           0.036587      0.064873         NaN       0.099758   \n",
       "KELLY_2016            0.085071      0.146838         NaN       0.048118   \n",
       "HEWITT_2016           0.065290      0.110241         NaN       0.074857   \n",
       "MCELVEEN_2016         0.135089      0.218751         NaN       0.024908   \n",
       "...                        ...           ...         ...            ...   \n",
       "EVANS_2012            0.117265      0.194772         NaN       0.030266   \n",
       "HARWOOD_2012          0.088870      0.150510         NaN       0.046810   \n",
       "UNKNOWN_2012          0.145333      0.231939         NaN       0.021743   \n",
       "MCELVEEN_2012         0.126173      0.203038         NaN       0.026784   \n",
       "BARTIROMO_2012        0.079014      0.134888         NaN       0.052706   \n",
       "WILLIAMS_2012         0.082238      0.141261         NaN       0.048686   \n",
       "GOV_2012              0.167043      0.255282         NaN       0.038233   \n",
       "BLITZER_2012          0.055295      0.067219         NaN       0.151299   \n",
       "TUMULTY_2012          0.103604      0.177230         NaN       0.033056   \n",
       "HARRIS_2012           0.086208      0.142201         NaN       0.051034   \n",
       "MALE_2012             0.134924      0.220024         NaN       0.020994   \n",
       "SANTORUM_2012         0.041296      0.023634         NaN       0.231137   \n",
       "RADDATZ_2012          0.082308      0.132105         NaN       0.067549   \n",
       "PRESIDENT_2012        0.043577      0.058929         NaN       0.122503   \n",
       "BACHMANN_2012         0.031101      0.035855         NaN       0.170958   \n",
       "BIDEN_2012            0.043115      0.066330         NaN       0.114183   \n",
       "RYAN_2012             0.042044      0.061545         NaN       0.115125   \n",
       "PERRY_2012            0.038610      0.032678         NaN       0.191964   \n",
       "HILLER_2012           0.137180      0.218016         NaN       0.026279   \n",
       "ROMNEY_2012           0.062980      0.025744         NaN       0.295166   \n",
       "DEMINT_2012           0.091869      0.160017         NaN       0.039581   \n",
       "CRAMER_2012           0.135347      0.219400         NaN       0.026066   \n",
       "HUNTSMAN_2012         0.032886      0.038903         NaN       0.149067   \n",
       "GOLDMAN_2012          0.126235      0.203244         NaN       0.030445   \n",
       "VAUGHN_2012           0.142137      0.227851         NaN       0.023988   \n",
       "MODERATOR_2012        0.065116      0.112681         NaN       0.069967   \n",
       "PAUL_2012             0.042974      0.025726         NaN       0.229302   \n",
       "GARRETT_2012          0.081984      0.138273         NaN       0.052902   \n",
       "PAWLENTY_2012         0.064352      0.120259         NaN       0.050482   \n",
       "LIESMAN_2012          0.168456      0.265124         NaN       0.025459   \n",
       "\n",
       "                  MUIR_2016  UNKNOWN_2016    ...          www      yeah  \\\n",
       "cand_name                                    ...                          \n",
       "HARWOOD_2016       0.043685      0.145370    ...     0.000000  0.000000   \n",
       "REGAN_2016         0.065107      0.106666    ...     0.038879  0.000000   \n",
       "HUCKABEE_2016      0.052628      0.239102    ...     0.000000  0.011801   \n",
       "MACCALLUM_2016     0.086792      0.080431    ...     0.056597  0.000000   \n",
       "FIORINA_2016       0.053909      0.252546    ...     0.000000  0.006045   \n",
       "CLINTON_2016       0.064454      0.364853    ...     0.000000  0.009292   \n",
       "WRITE_2016              NaN           NaN    ...     0.000000  0.000000   \n",
       "EPPERSON_2016      0.143906      0.050303    ...     0.000000  0.000000   \n",
       "MUIR_2016               NaN      0.239277    ...     0.026496  0.014104   \n",
       "UNKNOWN_2016       0.239277           NaN    ...     0.000000  0.000000   \n",
       "PAUL_2016          0.052091      0.229498    ...     0.000000  0.029990   \n",
       "CARSON_2016        0.053027      0.217820    ...     0.000000  0.006278   \n",
       "MITCHELL_2016      0.067644      0.110011    ...     0.000000  0.000000   \n",
       "QUICK_2016         0.045160      0.150354    ...     0.000000  0.000000   \n",
       "RUBIO_2016         0.061831      0.332453    ...     0.000000  0.042576   \n",
       "WEBB_2016          0.079083      0.105456    ...     0.000000  0.000000   \n",
       "COONEY_2016        0.126714      0.053418    ...     0.000000  0.000000   \n",
       "HEMMER_2016        0.079846      0.088591    ...     0.000000  0.000000   \n",
       "SANDERS_2016       0.074158      0.386896    ...     0.000000  0.036715   \n",
       "QUINTANILLA_2016   0.045596      0.142869    ...     0.058385  0.015539   \n",
       "CAVUTO_2016        0.040889      0.137403    ...     0.052155  0.000000   \n",
       "IFILL_2016         0.083043      0.080271    ...     0.054073  0.000000   \n",
       "COOPER_2016        0.025599      0.183372    ...     0.018529  0.000000   \n",
       "BUSH_2016          0.056238      0.294183    ...     0.000000  0.046852   \n",
       "BASH_2016          0.031107      0.180436    ...     0.000000  0.000000   \n",
       "BAKER_2016         0.070539      0.099221    ...     0.000000  0.000000   \n",
       "PATAKI_2016        0.050149      0.179973    ...     0.000000  0.022167   \n",
       "KELLY_2016         0.065711      0.097915    ...     0.000000  0.000000   \n",
       "HEWITT_2016        0.040809      0.144320    ...     0.000000  0.000000   \n",
       "MCELVEEN_2016      0.114381      0.057662    ...     0.000000  0.000000   \n",
       "...                     ...           ...    ...          ...       ...   \n",
       "EVANS_2012         0.104527      0.071957    ...     0.000000  0.000000   \n",
       "HARWOOD_2012       0.070659      0.102137    ...     0.044267  0.000000   \n",
       "UNKNOWN_2012       0.138886      0.055019    ...     0.000000  0.000000   \n",
       "MCELVEEN_2012      0.113072      0.061494    ...     0.000000  0.000000   \n",
       "BARTIROMO_2012     0.073083      0.113289    ...     0.000000  0.000000   \n",
       "WILLIAMS_2012      0.066961      0.107675    ...     0.032147  0.000000   \n",
       "GOV_2012           0.156506      0.066240    ...     0.000000  0.000000   \n",
       "BLITZER_2012       0.040263      0.247117    ...     0.025251  0.000000   \n",
       "TUMULTY_2012       0.103230      0.078622    ...     0.000000  0.000000   \n",
       "HARRIS_2012        0.072875      0.110977    ...     0.000000  0.000000   \n",
       "MALE_2012          0.126618      0.055647    ...     0.000000  0.000000   \n",
       "SANTORUM_2012      0.069904      0.349846    ...     0.000000  0.022115   \n",
       "RADDATZ_2012       0.069172      0.126802    ...     0.035801  0.000000   \n",
       "PRESIDENT_2012     0.051932      0.213219    ...     0.000000  0.000000   \n",
       "BACHMANN_2012      0.057892      0.279174    ...     0.000000  0.004541   \n",
       "BIDEN_2012         0.057872      0.199071    ...     0.000000  0.048700   \n",
       "RYAN_2012          0.056377      0.205953    ...     0.000000  0.009325   \n",
       "PERRY_2012         0.062690      0.301575    ...     0.000000  0.028146   \n",
       "HILLER_2012        0.123900      0.058449    ...     0.000000  0.000000   \n",
       "ROMNEY_2012        0.091369      0.427696    ...     0.004910  0.018296   \n",
       "DEMINT_2012        0.094712      0.091226    ...     0.000000  0.000000   \n",
       "CRAMER_2012        0.130421      0.053948    ...     0.000000  0.000000   \n",
       "HUNTSMAN_2012      0.053436      0.250870    ...     0.000000  0.000000   \n",
       "GOLDMAN_2012       0.115783      0.067885    ...     0.000000  0.000000   \n",
       "VAUGHN_2012        0.127324      0.058422    ...     0.000000  0.000000   \n",
       "MODERATOR_2012     0.054014      0.140182    ...     0.023462  0.000000   \n",
       "PAUL_2012          0.076200      0.348937    ...     0.000000  0.008602   \n",
       "GARRETT_2012       0.073273      0.114171    ...     0.000000  0.000000   \n",
       "PAWLENTY_2012      0.075059      0.113618    ...     0.000000  0.055529   \n",
       "LIESMAN_2012       0.159094      0.045152    ...     0.000000  0.000000   \n",
       "\n",
       "                      year     years       yes       yet      york     young  \\\n",
       "cand_name                                                                      \n",
       "HARWOOD_2016      0.000000  0.037513  0.010568  0.013081  0.015531  0.000000   \n",
       "REGAN_2016        0.022723  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "HUCKABEE_2016     0.025915  0.066378  0.010200  0.004208  0.009994  0.017561   \n",
       "MACCALLUM_2016    0.033078  0.000000  0.000000  0.000000  0.076535  0.000000   \n",
       "FIORINA_2016      0.033189  0.083464  0.055735  0.043116  0.005119  0.022490   \n",
       "CLINTON_2016      0.011478  0.023757  0.052203  0.006627  0.015737  0.057036   \n",
       "WRITE_2016        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "EPPERSON_2016     0.048185  0.044880  0.000000  0.000000  0.000000  0.000000   \n",
       "MUIR_2016         0.019357  0.032453  0.008127  0.005029  0.005972  0.005247   \n",
       "UNKNOWN_2016      0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "PAUL_2016         0.020580  0.026836  0.017280  0.016042  0.006349  0.011157   \n",
       "CARSON_2016       0.020679  0.048150  0.018086  0.000000  0.000000  0.004671   \n",
       "MITCHELL_2016     0.000000  0.000000  0.018965  0.000000  0.000000  0.000000   \n",
       "QUICK_2016        0.032695  0.030453  0.045755  0.000000  0.016811  0.000000   \n",
       "RUBIO_2016        0.010788  0.078709  0.011323  0.004672  0.000000  0.004873   \n",
       "WEBB_2016         0.013664  0.101815  0.000000  0.000000  0.000000  0.000000   \n",
       "COONEY_2016       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "HEMMER_2016       0.042096  0.078417  0.000000  0.000000  0.000000  0.000000   \n",
       "SANDERS_2016      0.031494  0.065708  0.072722  0.014729  0.005830  0.042682   \n",
       "QUINTANILLA_2016  0.042654  0.000000  0.000000  0.011082  0.013159  0.011561   \n",
       "CAVUTO_2016       0.038103  0.000000  0.000000  0.009900  0.011755  0.010328   \n",
       "IFILL_2016        0.047405  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "COOPER_2016       0.027074  0.025217  0.005683  0.000000  0.000000  0.007338   \n",
       "BUSH_2016         0.011691  0.039202  0.014725  0.003038  0.003607  0.003169   \n",
       "BASH_2016         0.000000  0.014156  0.023928  0.000000  0.000000  0.000000   \n",
       "BAKER_2016        0.018163  0.084587  0.038127  0.023596  0.000000  0.000000   \n",
       "PATAKI_2016       0.012170  0.022670  0.076638  0.007905  0.093858  0.000000   \n",
       "KELLY_2016        0.000000  0.015487  0.017452  0.021602  0.000000  0.000000   \n",
       "HEWITT_2016       0.000000  0.009453  0.000000  0.013185  0.015655  0.000000   \n",
       "MCELVEEN_2016     0.000000  0.000000  0.041344  0.000000  0.000000  0.000000   \n",
       "...                    ...       ...       ...       ...       ...       ...   \n",
       "EVANS_2012        0.077279  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "HARWOOD_2012      0.000000  0.012049  0.013577  0.000000  0.000000  0.017532   \n",
       "UNKNOWN_2012      0.000000  0.000000  0.066099  0.000000  0.000000  0.000000   \n",
       "MCELVEEN_2012     0.000000  0.114448  0.032242  0.000000  0.000000  0.000000   \n",
       "BARTIROMO_2012    0.000000  0.032119  0.000000  0.000000  0.000000  0.000000   \n",
       "WILLIAMS_2012     0.009394  0.026250  0.000000  0.036613  0.000000  0.038195   \n",
       "GOV_2012          0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "BLITZER_2012      0.018447  0.027491  0.011617  0.000000  0.000000  0.005000   \n",
       "TUMULTY_2012      0.060087  0.111931  0.000000  0.039030  0.000000  0.000000   \n",
       "HARRIS_2012       0.029334  0.013661  0.015394  0.019054  0.000000  0.000000   \n",
       "MALE_2012         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "SANTORUM_2012     0.031869  0.059367  0.014335  0.003943  0.004682  0.012340   \n",
       "RADDATZ_2012      0.020924  0.009744  0.010981  0.000000  0.016138  0.000000   \n",
       "PRESIDENT_2012    0.021248  0.091034  0.008920  0.000000  0.000000  0.086387   \n",
       "BACHMANN_2012     0.049864  0.055732  0.020934  0.016195  0.000000  0.006758   \n",
       "BIDEN_2012        0.074860  0.034862  0.005612  0.006947  0.000000  0.000000   \n",
       "RYAN_2012         0.071670  0.052449  0.010746  0.000000  0.007897  0.006938   \n",
       "PERRY_2012        0.026489  0.061679  0.013901  0.005735  0.003405  0.077780   \n",
       "HILLER_2012       0.056637  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ROMNEY_2012       0.037307  0.078850  0.017319  0.004660  0.003320  0.010695   \n",
       "DEMINT_2012       0.023507  0.021895  0.000000  0.000000  0.000000  0.000000   \n",
       "CRAMER_2012       0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "HUNTSMAN_2012     0.025799  0.048059  0.013539  0.000000  0.004974  0.004371   \n",
       "GOLDMAN_2012      0.075152  0.069997  0.078877  0.000000  0.000000  0.000000   \n",
       "VAUGHN_2012       0.000000  0.081641  0.045999  0.000000  0.000000  0.000000   \n",
       "MODERATOR_2012    0.034281  0.038316  0.007196  0.044536  0.000000  0.000000   \n",
       "PAUL_2012         0.033057  0.067443  0.049565  0.018405  0.000000  0.004267   \n",
       "GARRETT_2012      0.000000  0.000000  0.000000  0.018457  0.000000  0.000000   \n",
       "PAWLENTY_2012     0.000000  0.028394  0.000000  0.000000  0.000000  0.000000   \n",
       "LIESMAN_2012      0.000000  0.064236  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                  clusters  year_num  \n",
       "cand_name                             \n",
       "HARWOOD_2016             3      2016  \n",
       "REGAN_2016               0      2016  \n",
       "HUCKABEE_2016            1      2016  \n",
       "MACCALLUM_2016           0      2016  \n",
       "FIORINA_2016             1      2016  \n",
       "CLINTON_2016             1      2016  \n",
       "WRITE_2016               7      2016  \n",
       "EPPERSON_2016            7      2016  \n",
       "MUIR_2016                3      2016  \n",
       "UNKNOWN_2016             7      2016  \n",
       "PAUL_2016                1      2016  \n",
       "CARSON_2016              1      2016  \n",
       "MITCHELL_2016            6      2016  \n",
       "QUICK_2016               3      2016  \n",
       "RUBIO_2016               1      2016  \n",
       "WEBB_2016                1      2016  \n",
       "COONEY_2016              7      2016  \n",
       "HEMMER_2016              3      2016  \n",
       "SANDERS_2016             1      2016  \n",
       "QUINTANILLA_2016         0      2016  \n",
       "CAVUTO_2016              0      2016  \n",
       "IFILL_2016               0      2016  \n",
       "COOPER_2016              6      2016  \n",
       "BUSH_2016                1      2016  \n",
       "BASH_2016                3      2016  \n",
       "BAKER_2016               3      2016  \n",
       "PATAKI_2016              1      2016  \n",
       "KELLY_2016               3      2016  \n",
       "HEWITT_2016              3      2016  \n",
       "MCELVEEN_2016            3      2016  \n",
       "...                    ...       ...  \n",
       "EVANS_2012               2      2012  \n",
       "HARWOOD_2012             2      2012  \n",
       "UNKNOWN_2012             7      2012  \n",
       "MCELVEEN_2012            2      2012  \n",
       "BARTIROMO_2012           2      2012  \n",
       "WILLIAMS_2012            2      2012  \n",
       "GOV_2012                 7      2012  \n",
       "BLITZER_2012             2      2012  \n",
       "TUMULTY_2012             7      2012  \n",
       "HARRIS_2012              2      2012  \n",
       "MALE_2012                7      2012  \n",
       "SANTORUM_2012            1      2012  \n",
       "RADDATZ_2012             0      2012  \n",
       "PRESIDENT_2012           1      2012  \n",
       "BACHMANN_2012            1      2012  \n",
       "BIDEN_2012               1      2012  \n",
       "RYAN_2012                1      2012  \n",
       "PERRY_2012               1      2012  \n",
       "HILLER_2012              2      2012  \n",
       "ROMNEY_2012              1      2012  \n",
       "DEMINT_2012              7      2012  \n",
       "CRAMER_2012              7      2012  \n",
       "HUNTSMAN_2012            1      2012  \n",
       "GOLDMAN_2012             2      2012  \n",
       "VAUGHN_2012              7      2012  \n",
       "MODERATOR_2012           2      2012  \n",
       "PAUL_2012                1      2012  \n",
       "GARRETT_2012             2      2012  \n",
       "PAWLENTY_2012            1      2012  \n",
       "LIESMAN_2012             7      2012  \n",
       "\n",
       "[351 rows x 1356 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
